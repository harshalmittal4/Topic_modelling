{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim\n",
    "#import fasttext as ft\n",
    "import re\n",
    "import itertools\n",
    "import collections \n",
    "import nltk\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "articles = pd.read_csv('Tweets.csv')\n",
    "#articles = articles1.iloc[:100,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "start = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def topic_generation(x):\n",
    "    doc_complete = nltk.sent_tokenize(x.decode('utf-8')) # convert each training example to a list of documents\n",
    "    stop = set(nltk.corpus.stopwords.words('english')) #to remove stopwords\n",
    "    exclude = set(string.punctuation)                     #to remove punctuations\n",
    "    lemma = nltk.stem.wordnet.WordNetLemmatizer()       #to correct slang and return the base word\n",
    "    \n",
    "    def clean(doc):\n",
    "        stop_free = \" \".join([i for i in doc.lower().split() if i not in stop])\n",
    "        punc_free = ''.join(ch for ch in stop_free if ch not in exclude)\n",
    "        normalized = \" \".join(lemma.lemmatize(word) for word in punc_free.split())\n",
    "        return normalized                             \n",
    "\n",
    "    doc_clean = [clean(doc).split() for doc in doc_complete]   #list of docs where each doc contains its important words\n",
    "    dictionary = gensim.corpora.Dictionary(doc_clean)          \n",
    "\n",
    "    # Converting list of documents (corpus) into Document Term Matrix using dictionary prepared above.\n",
    "    doc_term_matrix = [dictionary.doc2bow(doc) for doc in doc_clean]\n",
    "    Lda = gensim.models.ldamodel.LdaModel\n",
    "\n",
    "    # Running and Trainign LDA model on the document term matrix.\n",
    "    try:\n",
    "        ldamodel = Lda(doc_term_matrix, num_topics=len(doc_complete), id2word = dictionary, passes=20)\n",
    "        topic_list = []\n",
    "\n",
    "        topics = ldamodel.show_topics(num_topics = len(doc_complete), num_words = 1) # num_words-no.of words under 1 topic(the one with the highest prob. for that topic)\n",
    "        for i in range(len(topics)):\n",
    "            if topics[i][1][7:-1] not in topic_list:\n",
    "                topic_list.append(topics[i][1][7:-1])\n",
    "        return topic_list\n",
    "\n",
    "    except ValueError:\n",
    "        pass\n",
    "   \n",
    "articles['topics'] = articles.text.map(lambda x:topic_generation(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                                [dhepburn]\n",
       "1                                   [added]\n",
       "2                                 [another]\n",
       "3                              [aggressive]\n",
       "4                                     [bad]\n",
       "5                         [playing, flying]\n",
       "6                                    [away]\n",
       "7         [httpstcomwpg7grezp, opportunity]\n",
       "8                                 [well, d]\n",
       "9                             [early, good]\n",
       "10                                   [1024]\n",
       "11                [d, graphic, iconography]\n",
       "12                 [p, trip, virginamerica]\n",
       "13                         [fabulous, take]\n",
       "14                                 [thanks]\n",
       "15                                    [mia]\n",
       "16                      [cross, 29daystogo]\n",
       "17                              [help, nyc]\n",
       "18                     [virginamerica, ‚ò∫Ô∏èüëç]\n",
       "19                 [please, fly, amazingly]\n",
       "20                          [time, carrier]\n",
       "21       [virginamerica, httptcout5grrwaaa]\n",
       "22                             [love, feel]\n",
       "23                                [anytime]\n",
       "24                      [internet, seating]\n",
       "25              [applied, status, response]\n",
       "26                                  [2, ur]\n",
       "27                [virginamerica, together]\n",
       "28                         [sfotobos, cold]\n",
       "29                  [sendambien, red, noob]\n",
       "                        ...                \n",
       "14610              [outrageous, understand]\n",
       "14611                     [retribution, so]\n",
       "14612                [flight, help, anyway]\n",
       "14613                     [pleasehelp, got]\n",
       "14614             [backwards, calling, 8am]\n",
       "14615                         [sat, flight]\n",
       "14616                 [earlier, aa, flight]\n",
       "14617                    [americanair, big]\n",
       "14618            [luggage, seriously, 3078]\n",
       "14619                  [situation, company]\n",
       "14620                                 [1st]\n",
       "14621             [cant, help, americanair]\n",
       "14622                       [accommodation]\n",
       "14623                [nocharge, one, plane]\n",
       "14624                         [call, today]\n",
       "14625             [landing, 236, fantastic]\n",
       "14626            [nycbuenos, answer, going]\n",
       "14627          [americanair, flight, first]\n",
       "14628                       [review, thank]\n",
       "14629                         [americanair]\n",
       "14630                     [is, americanair]\n",
       "14631               [on, u, another, plane]\n",
       "14632                        [george, link]\n",
       "14633                              [flight]\n",
       "14634                         [americanair]\n",
       "14635                         [americanair]\n",
       "14636                    [called, late, 20]\n",
       "14637                             [airline]\n",
       "14638            [flight, make, suggestion]\n",
       "14639                           [4, flight]\n",
       "Name: topics, dtype: object"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "articles['topics']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop=time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "954.9847421646118"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stop-start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
